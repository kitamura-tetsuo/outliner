name: Test

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
    types: [opened, synchronize, reopened, ready_for_review]
  workflow_run:
    workflows: ["Format Check and Auto-Fix"]
    types:
      - completed
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref == 'refs/heads/main' && github.run_id || github.ref }}
  cancel-in-progress: true

jobs:
  test:
    # Only run if formatter workflow succeeded (for workflow_run) or for direct triggers
    # Skip if this is a push event and the commit message indicates auto-formatting
    if: |
      (github.event_name != 'workflow_run' || github.event.workflow_run.conclusion == 'success') &&
      !(github.event_name == 'push' && contains(github.event.head_commit.message, 'Auto-fix: Format code with dprint'))
    runs-on: ubuntu-latest
    timeout-minutes: 45
    permissions:
      contents: write
      pull-requests: write

    steps:
      - name: Debug workflow trigger
        run: |
          echo "Event name: ${{ github.event_name }}"
          echo "Ref: ${{ github.ref }}"
          echo "Head ref: ${{ github.head_ref }}"
          echo "Base ref: ${{ github.base_ref }}"
          echo "Repository: ${{ github.repository }}"
          echo "Actor: ${{ github.actor }}"
          echo "Workflow: ${{ github.workflow }}"
          echo "Run ID: ${{ github.run_id }}"
          echo "Run number: ${{ github.run_number }}"

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          clean: true             # wipe workspace before fetch
          # For workflow_run events, checkout the head commit that triggered the formatter workflow
          ref: ${{ github.event_name == 'workflow_run' && github.event.workflow_run.head_sha || github.sha }}
          # For PR events, ensure we have write permissions for auto-formatting
          token: ${{ github.event_name == 'pull_request' && secrets.GITHUB_TOKEN || github.token }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          registry-url: 'https://registry.npmjs.org'

      - name: Install dprint
        run: npm install -g dprint

      - name: Check and fix formatting
        id: format_check
        run: |
          echo "Running formatting check..."
          if ! ./scripts/check_format.sh; then
            echo "‚ùå Code is not properly formatted!"
            echo "üîß Auto-fixing formatting issues..."
            npx dprint fmt

            # Check if there are any changes
            if git diff --quiet; then
              echo "No changes were made by dprint fmt"
              echo "format_fixed=false" >> $GITHUB_OUTPUT
            else
              # Configure git
              git config --local user.email "action@github.com"
              git config --local user.name "GitHub Action"

              # Only auto-commit for push/PR events, not workflow_run
              if [[ "${{ github.event_name }}" == "push" || "${{ github.event_name }}" == "pull_request" ]]; then
                # Check if we're behind remote to avoid conflicts
                git fetch origin
                if git merge-base --is-ancestor HEAD origin/${{ github.ref_name }}; then
                  git add .
                  git commit -m "Auto-fix: Format code with dprint"

                  # Retry push with pull if needed
                  if ! git push; then
                    echo "Push failed, trying to pull and retry..."
                    git pull --rebase origin ${{ github.ref_name }}
                    git push
                  fi
                  echo "‚úÖ Formatting issues have been automatically fixed and committed!"
                else
                  echo "‚ö†Ô∏è Local branch is behind remote, skipping auto-commit to avoid conflicts"
                  echo "Please pull latest changes and run 'npx dprint fmt' manually"
                fi
              fi
              echo "format_fixed=true" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚úÖ All code is properly formatted!"
            echo "format_fixed=false" >> $GITHUB_OUTPUT
          fi

      - name: Check environment
        run: |
          echo "Node version: $(node --version)"
          echo "NPM version: $(npm --version)"
          echo "Current user: $(whoami)"
          echo "Working directory: $(pwd)"
          echo "PATH: $PATH"

      - name: Load NVM environment
        run: |
          # Load NVM if available
          if [ -d "$HOME/.nvm" ] && [ -s "$HOME/.nvm/nvm.sh" ]; then
            . "$HOME/.nvm/nvm.sh"
            echo "NVM loaded, Node version: $(node --version)"
            echo "NPM version: $(npm --version)"
          fi

          # Check if actions/setup-node installed Node.js in _tool directory
          if [ -d "$GITHUB_WORKSPACE/../_tool/node" ]; then
            NODE_TOOL_DIR=$(find "$GITHUB_WORKSPACE/../_tool/node" -name "x64" -type d | head -1)
            if [ -n "$NODE_TOOL_DIR" ]; then
              export PATH="$NODE_TOOL_DIR/bin:$PATH"
              echo "Found Node.js in tool cache: $(node --version)"
              echo "NPM version: $(npm --version)"
            fi
          fi

          # Fallback: try to use system Node.js if actions/setup-node didn't work
          if ! command -v node >/dev/null 2>&1; then
            echo "Node.js not found via actions/setup-node, trying system installation..."
            # Try common Node.js installation paths
            export PATH="/usr/local/bin:/usr/bin:$PATH"
            if command -v node >/dev/null 2>&1; then
              echo "Found system Node.js: $(node --version)"
            else
              echo "Node.js not found in system paths either"
              exit 1
            fi
          fi

          # Verify npm is available
          if ! command -v npm >/dev/null 2>&1; then
            echo "npm not found, this will cause issues in subsequent steps"
            exit 1
          fi

          # Export PATH for subsequent steps
          echo "PATH=$PATH" 2>&1 | tee -a $GITHUB_ENV

      - name: Install dependencies
        run: |
          # Load NVM if available
          if [ -d "$HOME/.nvm" ] && [ -s "$HOME/.nvm/nvm.sh" ]; then
            . "$HOME/.nvm/nvm.sh"
            echo "NVM loaded, Node version: $(node --version)"
            echo "NPM version: $(npm --version)"
          fi

          # Verify npm is available
          if ! command -v npm >/dev/null 2>&1; then
            echo "Error: npm command not found"
            echo "PATH: $PATH"
            echo "Node location: $(which node || echo 'node not found')"
            exit 1
          fi

          # Install root dependencies if package.json exists
          if [ -f "package.json" ]; then
            echo "Installing root dependencies..."
            # Try npm ci first, fallback to npm install if lock files are out of sync
            npm ci || {
              echo "npm ci failed, trying npm install..."
              npm install
            }
          fi

          # Install client dependencies
          echo "Installing client dependencies..."
          if [ -d "client" ] && [ -f "client/package.json" ]; then
            cd client
            # Try npm ci first, fallback to npm install if lock files are out of sync
            npm ci || {
              echo "npm ci failed for client, trying npm install..."
              npm install
            }
            # Compile Paraglide messages
            echo "Compiling Paraglide messages..."
            npm run paraglide:compile || echo "Paraglide compilation failed, continuing..."
            cd ..
          else
            echo "Client directory or package.json not found"
            exit 1
          fi

          # Install server dependencies
          echo "Installing server dependencies..."
          if [ -d "server" ] && [ -f "server/package.json" ]; then
            cd server
            # Try npm ci first, fallback to npm install if lock files are out of sync
            npm ci || {
              echo "npm ci failed for server, trying npm install..."
              npm install
            }
            cd ..
          else
            echo "Server directory or package.json not found"
            exit 1
          fi

          # Install functions dependencies
          echo "Installing functions dependencies..."
          if [ -d "functions" ] && [ -f "functions/package.json" ]; then
            cd functions
            # Try npm ci first, fallback to npm install if lock files are out of sync
            npm ci || {
              echo "npm ci failed for functions, trying npm install..."
              npm install
            }
            cd ..
          else
            echo "Functions directory or package.json not found"
            exit 1
          fi

      - name: Setup Java for Firebase emulator
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Setup test environment
        run: |
          # Load NVM if available
          if [ -d "$HOME/.nvm" ] && [ -s "$HOME/.nvm/nvm.sh" ]; then
            . "$HOME/.nvm/nvm.sh"
          fi

          # Verify Java installation
          echo "Java version: $(java -version 2>&1 | head -1)"

          # Install global packages if needed (without sudo for self-hosted runner)
          echo "Installing global packages..."
          if ! command -v firebase >/dev/null || ! command -v tinylicious >/dev/null; then
            npm install -g firebase-tools tinylicious dotenv-cli cross-env @dotenvx/dotenvx || echo "Global package installation failed, continuing..."
          fi

          # Install OS utilities if needed
          echo "Installing OS utilities..."
          if ! command -v xvfb-run &> /dev/null || ! command -v lsof &> /dev/null; then
            sudo apt-get update
            sudo apt-get install -y xvfb lsof netcat-openbsd curl
          fi

          # Clean up any existing processes on test ports
          echo "Cleaning up existing processes..."
          cd "$(pwd)"
          if [ -f "scripts/kill-tinylicious.js" ]; then
            node scripts/kill-tinylicious.js || echo "Process cleanup script failed, continuing..."
          fi

          # Manual cleanup as fallback
          pkill -f "port 7090" || true
          pkill -f "port 7091" || true
          pkill -f "port 7092" || true
          pkill -f "port 7093" || true
          pkill -f "port 59099" || true
          pkill -f "port 58080" || true
          pkill -f "port 57000" || true
          pkill -f "tinylicious" || true
          pkill -f "firebase" || true
          pkill -f "vite" || true

          # Wait for ports to be freed
          sleep 5

      - name: Install Playwright browsers
        run: |
          # Load NVM if available
          if [ -d "$HOME/.nvm" ] && [ -s "$HOME/.nvm/nvm.sh" ]; then
            . "$HOME/.nvm/nvm.sh"
          fi

          cd client
          echo "Installing Playwright browsers..."
          npx playwright install --with-deps || echo "Playwright install failed, continuing..."

      - name: Build client
        run: |
          cd client
          npm run build

      - name: Lint functions
        run: |
          cd functions
          npm run lint -- --fix

      - name: Firebase deployment dry run
        run: |
          # Create temporary env file for functions (similar to deploy workflow)
          cat > functions/.env <<EOF
          AZURE_TENANT_ID=test-tenant-id
          AZURE_ENDPOINT=https://test.fluidrelay.azure.com
          AZURE_PRIMARY_KEY=test-primary-key
          AZURE_SECONDARY_KEY=test-secondary-key
          AZURE_ACTIVE_KEY=primary
          NODE_ENV=test
          EOF

          # Set Firebase project for testing
          firebase use outliner-d57b0 --token "${{ secrets.FIREBASE_TOKEN }}"

          # Validate Firebase configuration and functions
          echo "Validating Firebase configuration..."
          firebase functions:config:get --project outliner-d57b0 --token "${{ secrets.FIREBASE_TOKEN }}" || echo "No config found"

          # Check functions source code for syntax errors
          echo "Checking functions source code..."
          cd functions
          node -c index.js
          cd ..

          # Validate Firebase project configuration
          echo "Validating Firebase project configuration..."
          firebase projects:list --token "${{ secrets.FIREBASE_TOKEN }}" | grep outliner-d57b0

          # Validate functions deployment (dry run)
          echo "Performing Firebase Functions deployment validation..."
          firebase deploy --only functions --project outliner-d57b0 --token "${{ secrets.FIREBASE_TOKEN }}" --dry-run || {
            echo "‚ùå Firebase deployment validation failed!"
            echo "This indicates that the deployment would fail in production."
            exit 1
          }

          echo "‚úÖ Firebase deployment validation passed!"

          # Additional validation for other Firebase services
          echo "Validating Firebase Hosting configuration..."
          firebase hosting:channel:list --project outliner-d57b0 --token "${{ secrets.FIREBASE_TOKEN }}" || echo "No hosting channels found"

          # Validate Firestore rules
          echo "Validating Firestore rules..."
          firebase firestore:rules:get --project outliner-d57b0 --token "${{ secrets.FIREBASE_TOKEN }}" || echo "No Firestore rules found"

          # Validate Storage rules
          echo "Validating Storage rules..."
          firebase storage:rules:get --project outliner-d57b0 --token "${{ secrets.FIREBASE_TOKEN }}" || echo "No Storage rules found"

          echo "‚úÖ All Firebase services validation completed!"
        env:
          CI: true

      - name: Run codex setup script
        run: bash scripts/setup.sh
        env:
          CI: true
          NODE_ENV: test
          TEST_ENV: localhost
          DISPLAY: :99
          DISABLE_POSTHOG: true
          VITE_DISABLE_FLUID_TELEMETRY: true

      # - name: Run environment tests
      #   run: |
      #     bash scripts/run-env-tests.sh 2>&1 | tee -a /tmp/env-test.log
      #   env:
      #     CI: true
      #     NODE_ENV: test
      #     TEST_ENV: localhost
      #     DISPLAY: :99
      #     DISABLE_POSTHOG: true
      #     VITE_DISABLE_FLUID_TELEMETRY: true

      - name: Run unit and integration tests for github reporting
        run: |
          set -o pipefail
          mkdir -p job_logs/${{ github.job }}
          cd client
          npm run github:test:unit 2>&1 | tee -a ../job_logs/${{ github.job }}/unit-test.log
          npm run github:test:integration 2>&1 | tee -a ../job_logs/${{ github.job }}/integration-test.log
        env:
          CI: true
          NODE_ENV: test
          TEST_ENV: localhost
          DISPLAY: :99
          DISABLE_POSTHOG: true
          VITE_DISABLE_FLUID_TELEMETRY: true

      - name: Run e2e tests for github reporting
        run: |
          set -o pipefail
          mkdir -p job_logs/${{ github.job }}
          cd client
          npm run github:test:e2e 2>&1 | tee -a ../job_logs/${{ github.job }}/e2e-test.log
        env:
          CI: true
          NODE_ENV: test
          TEST_ENV: localhost
          DISPLAY: :99
          DISABLE_POSTHOG: true
          VITE_DISABLE_FLUID_TELEMETRY: true

      - name: Summarise failures
        if: failure()
        run: |
          echo "## ‚ùå Test suite failed" 2>&1 | tee -a "$GITHUB_STEP_SUMMARY"
          echo 2>&1 | tee -a "$GITHUB_STEP_SUMMARY"

          # Check for test failures in job-specific logs
          JOB_LOG_DIR="job_logs/${{ github.job }}"

          if [ -f "$JOB_LOG_DIR/unit-test.log" ]; then
            echo "### Unit Test Failures:" 2>&1 | tee -a "$GITHUB_STEP_SUMMARY"
            grep -E -A1 -B0 "FAIL|FAILED" "$JOB_LOG_DIR/unit-test.log" 2>&1 | tee -a "$GITHUB_STEP_SUMMARY" || true
            echo 2>&1 | tee -a "$GITHUB_STEP_SUMMARY"
          fi

          if [ -f "$JOB_LOG_DIR/integration-test.log" ]; then
            echo "### Integration Test Failures:" 2>&1 | tee -a "$GITHUB_STEP_SUMMARY"
            grep -E -A1 -B0 "FAIL|FAILED" "$JOB_LOG_DIR/integration-test.log" 2>&1 | tee -a "$GITHUB_STEP_SUMMARY" || true
            echo 2>&1 | tee -a "$GITHUB_STEP_SUMMARY"
          fi

          if [ -f "$JOB_LOG_DIR/e2e-test.log" ]; then
            echo "### E2E Test Failures:" 2>&1 | tee -a "$GITHUB_STEP_SUMMARY"
            grep -E -A1 -B0 "FAIL|FAILED" "$JOB_LOG_DIR/e2e-test.log" 2>&1 | tee -a "$GITHUB_STEP_SUMMARY" || true
            echo 2>&1 | tee -a "$GITHUB_STEP_SUMMARY"
          fi

          # Check for Firebase deployment validation failures
          echo "### Firebase Deployment Validation:" 2>&1 | tee -a "$GITHUB_STEP_SUMMARY"
          echo "If Firebase deployment validation failed, this indicates that the production deployment would also fail." 2>&1 | tee -a "$GITHUB_STEP_SUMMARY"
          echo "Please check the Firebase configuration, functions code, and secrets setup." 2>&1 | tee -a "$GITHUB_STEP_SUMMARY"

      - name: Check disk space before upload
        if: failure()
        id: disk-check
        run: |
          # Check available disk space (in GB)
          AVAILABLE_GB=$(df -BG . | awk 'NR==2 {print $4}' | sed 's/G//')
          echo "Available disk space: ${AVAILABLE_GB}GB"

          # Set minimum required space (2GB)
          MIN_SPACE=2

          if [ "$AVAILABLE_GB" -gt "$MIN_SPACE" ]; then
            echo "sufficient_space=true" 2>&1 | tee -a $GITHUB_OUTPUT
            echo "‚úÖ Sufficient disk space available for artifact upload"
          else
            echo "sufficient_space=false" 2>&1 | tee -a $GITHUB_OUTPUT
            echo "‚ö†Ô∏è Insufficient disk space for artifact upload (${AVAILABLE_GB}GB < ${MIN_SPACE}GB)"
          fi

      - name: cat log
        if: failure()
        run: |
          if [ -f "server/logs/test-log-service-tee.log" ]; then
            echo "=== API Server Log ==="
            cat server/logs/test-log-service-tee.log
          else
            echo "‚ö†Ô∏è Log file server/logs/test-log-service-tee.log not found"
            echo "This may indicate that the setup script (scripts/setup.sh) failed to start the API server"
            echo "Checking for other log files..."
            if [ -f "server/logs/firebase-emulator.log" ]; then
              echo "=== Firebase Emulator Log ==="
              cat server/logs/firebase-emulator.log
            fi
            if [ -f "server/logs/yjs-websocket.log" ]; then
              echo "=== Yjs WebSocket Log ==="
              cat server/logs/yjs-websocket.log
            fi
            if [ -f "server/logs/test-svelte-kit.log" ]; then
              echo "=== SvelteKit Log ==="
              cat server/logs/test-svelte-kit.log
            fi
          fi

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: failure() && steps.disk-check.outputs.sufficient_space == 'true'
        continue-on-error: true
        with:
          name: test-results-${{ github.run_id }}
          path: |
            client/test-results/
            client/playwright-report/
            coverage/
            server/logs/
            client/logs/
          retention-days: 2

      - name: Cleanup after tests
        if: always()
        run: |
          echo "Starting cleanup process..."

          # Use the cleanup script if available
          if [ -f "scripts/kill-tinylicious.js" ]; then
            node scripts/kill-tinylicious.js || echo "Cleanup script failed"
          fi

          # Manual cleanup as fallback
          pkill -f "tinylicious" || true
          pkill -f "firebase" || true
          pkill -f "vite" || true
          pkill -f "node.*7090" || true
          pkill -f "node.*7091" || true
          pkill -f "node.*7092" || true
          pkill -f "node.*7093" || true
          pkill -f "node.*59099" || true
          pkill -f "node.*58080" || true
          pkill -f "node.*57000" || true

          # Wait for processes to terminate
          sleep 3

          # Show any remaining processes
          echo "Remaining processes:"
          ps aux | grep -E "(tinylicious|firebase|vite|node.*70|node.*59|node.*58|node.*57)" || echo "No relevant processes found"

          # Clean up job-specific log directories
          echo "Cleaning up job-specific log directories..."
          rm -rf job_logs/ || echo "No job_logs directory to clean up"

      - name: Comment PR with test results
        uses: actions/github-script@v7
        if: github.event_name == 'pull_request' && always()
        with:
          script: |
            const testStatus = '${{ job.status }}';
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;

            let comment = '## üß™ Test Results\n\n';

            if (testStatus === 'success') {
              comment += '‚úÖ **All tests passed!** üéâ\n\n';
              comment += 'üöÄ **Firebase deployment validation:** ‚úÖ Passed\n\n';
            } else if (testStatus === 'cancelled') {
              comment += '‚èπÔ∏è **Tests were cancelled** - You may want to restart the tests.\n\n';
            } else {
              comment += '‚ùå **Tests failed** - Please check the logs and fix the failing tests.\n\n';
              comment += 'üî• **Firebase deployment validation:** May have failed - check logs for deployment issues\n\n';
              comment += 'ü§ñ **Auto-fix:** Claude Code Action will automatically attempt to fix the failing tests.\n\n';
            }

            comment += `üìä [View detailed results](${runUrl})\n`;
            comment += `üîç [View all checks](${context.payload.pull_request.html_url}/checks)\n\n`;
            comment += `**Commit:** ${context.sha.substring(0, 7)}`;

            try {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } catch (error) {
              console.error('Failed to create PR comment:', error);
            }
